---
title: "ST558 Final Project Modeling Document"
author: "Kyra Kapsaskis"
format: html
editor: visual
---

# Splitting the data into a test and training set


```{r}
# set a seed for reproducibility
set.seed(101)

split <- createDataPartition(y = factor_data$Diabetes_factor, p = 0.7, list = FALSE)
train <- factor_data[split, ]
test <- factor_data[-split, ]

```

# fit three candidate logistic regression models and choose the best model using CV with log-loss as your metric.


```{r}
# defining cv arguments that will be used as an argument inside each model function

cv_settings <- trainControl(method = "cv", number = 5, summaryFunction = mnLogLoss, classProbs = TRUE) #need to change this to five
```

## First Logistic Regression


```{r}
library(rpart)
```

```{r}
# running three separate logistic regressions with different predictors
```

```{r}

my_logreg_1 <- train(Diabetes_factor ~ Sex_factor + Age_factor + HighChol_factor,
                     data = train, 
                     method = "glm",
                      
                     trControl = cv_settings,
                     metric = "logLoss")
my_logreg_1
log1_predict <- predict(my_logreg_1, test)

summary(log1_predict)

```

## Second Logistic Regression

```{r}

my_logreg_2 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")

my_logreg_2

log2_predict <- predict(my_logreg_2, test)

summary(log2_predict)

```

```{r}
# random testing out the describe function
describe(factor_data$Diabetes_factor)
```

## Third Logistic Regression

```{r}

my_logreg_3 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor + Fruits_factor + GenHlth_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")
my_logreg_3

log3_predict <- predict(my_logreg_3, test)

summary(log3_predict)
```

## Confusion Matrices

```{r}
confusionMatrix(log1_predict, test$Diabetes_factor)
confusionMatrix(log2_predict, test$Diabetes_factor)
confusionMatrix(log3_predict, test$Diabetes_factor)
```
# First log model
###  logLoss  
###  0.3709215
# Second log model
###  logLoss  
###  0.3791157
# Third log model
###  logLoss  
###  0.3445646

# Tree models

```{r}
library(tidyverse)
library(haven)
library(knitr)
library(rgl)
library(tree)
library(caret)
```

```{r}
# one tree and one rf, put a lot more predictors, change tunegrid for this and 
```

```{r}
my_tree <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.1, 0.001)))


my_tree_predict <- predict(my_tree, test)

summary(my_tree_predict)

```

```{r}
my_tree
```


```{r}
my_tree_2 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.5, 0.01)))


my_tree_2_predict <- predict(my_tree_2, test)

summary(my_tree_2_predict)
```
```{r}
my_tree_2
```

```{r}
my_tree_3 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.01, 0.0001)))

my_tree_3_predict <- predict(my_tree_3, test)

summary(my_tree_3_predict)

my_tree_3
```

```{r}
#Confusion Matrices

confusionMatrix(my_tree_predict, test$Diabetes_factor)
confusionMatrix(my_tree_2_predict, test$Diabetes_factor)
confusionMatrix(my_tree_3_predict, test$Diabetes_factor)
```

# First tree parameters
###  logLoss  
###  0.3635067
# Second log model
###  logLoss  
###  0.3608280
# Third log model
###  logLoss  
###  0.3587766


```{r}
library(ranger)
```

# Random Forest

```{r}

# put a lot of predictors, mtry is a sequence EXAMPLE MAYBE...seq(1, 10, 3)
# just one 
# then pick between logistic 1, 2, 3, tree parameter 1, 2, 3, and rf which mtry was best
set.seed(10)
rfFit <- train(Diabetes_factor ~ Age_factor + Sex_factor + HvyAlcoholConsump_factor + PhysActivity_factor + HighChol_factor + HighBP_factor + GenHlth_factor + AnyHealthcare_factor,
               data = train,
               method = "ranger",
               trControl = trainControl(method = "cv",
                                        number = 3),
               preProcess = c("center", "scale"),
               tuneGrid = data.frame(mtry = seq(1, 10, 3), splitrule="gini", min.node.size=1
                                     )
               )
rfFit
```
