---
title: "ST558 Final Project Modeling Document"
author: "Kyra Kapsaskis"
format: html
editor: visual
---

#### Splitting the data into a test and training set

```{r}
library(caret)
```

```{r}
# set a seed for reproducibility
set.seed(101)

split <- createDataPartition(y = factor_data$Diabetes_factor, p = 0.7, list = FALSE)
train <- factor_data[split, ]
test <- factor_data[-split, ]

```

#### Let's fit three different logistic regression models, where we change the predictors in each model and see which one is the best!

```{r}
# defining cv arguments that will be used as an argument inside each model function

cv_settings <- trainControl(method = "cv", number = 5, summaryFunction = mnLogLoss, classProbs = TRUE) #need to change this to five
```

### First Logistic Regression

```{r}
library(rpart)
```

```{r}

my_logreg_1 <- train(Diabetes_factor ~ Sex_factor + Age_factor + HighChol_factor,
                     data = train, 
                     method = "glm",
                      
                     trControl = cv_settings,
                     metric = "logLoss")
my_logreg_1
log1_predict <- predict(my_logreg_1, test)

summary(log1_predict)

```

### Second Logistic Regression

```{r}

my_logreg_2 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")

my_logreg_2

log2_predict <- predict(my_logreg_2, test)

summary(log2_predict)

```

```{r}
# random testing out the describe function
describe(factor_data$Diabetes_factor)
```

### Third Logistic Regression

```{r}

my_logreg_3 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor + Fruits_factor + GenHlth_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")
my_logreg_3

log3_predict <- predict(my_logreg_3, test)

summary(log3_predict)
```

The third model had the lowest log loss, so that would be the best one here.

#### Confusion Matrices

```{r}
confusionMatrix(log1_predict, test$Diabetes_factor)
confusionMatrix(log2_predict, test$Diabetes_factor)
confusionMatrix(log3_predict, test$Diabetes_factor)
```

#### First log model

logLoss

0.3709215

#### Second log model

logLoss

0.3791157

#### Third log model - best one!!!

logLoss

0.3445646

## Tree models

```{r}
library(tidyverse)
library(haven)
library(knitr)
library(rgl)
library(tree)
library(caret)
```

Now we are going to fit three different Classification Tree models, but instead of changing predictors, we will change the tuning parameters instead, and see which ones produce the best outcome.

### First tree model

```{r}
my_tree <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.1, 0.001)))


my_tree_predict <- predict(my_tree, test)

summary(my_tree_predict)

```

```{r}
my_tree
```

### Second tree model

with adjusted tuning parameters to see what happens

```{r}
my_tree_2 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.5, 0.01)))


my_tree_2_predict <- predict(my_tree_2, test)

summary(my_tree_2_predict)
```

```{r}
my_tree_2
```

#### Third Tree Model

with adjusted parameters in the other direction

```{r}
my_tree_3 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.01, 0.0001)))

my_tree_3_predict <- predict(my_tree_3, test)

summary(my_tree_3_predict)

my_tree_3
```

So far, this third tree looks like the best one, for the same reason as above looking at the log loss.

```{r}
#Confusion Matrices

confusionMatrix(my_tree_predict, test$Diabetes_factor)
confusionMatrix(my_tree_2_predict, test$Diabetes_factor)
confusionMatrix(my_tree_3_predict, test$Diabetes_factor)
```

#### First tree parameters

logLoss

0.3635067

#### Second log model

logLoss

0.3608280

#### Third log model - best one!!!

logLoss

0.3573305

```{r}
library(ranger)
```

### Random Forest model time!

This one will be different because instead of changing the predictors we will change the 'mtry' value. First we will fit a sequence of mtry's and see which one is best.

```{r}

set.seed(10)
rfFit <- train(Diabetes_factor ~ Age_factor + Sex_factor + HvyAlcoholConsump_factor + PhysActivity_factor + HighChol_factor + HighBP_factor + GenHlth_factor + AnyHealthcare_factor,
               data = train,
               method = "ranger",
               trControl = trainControl(method = "cv",
                                        number = 3),
               preProcess = c("center", "scale"),
               tuneGrid = data.frame(mtry = seq(1, 10, 3), splitrule="gini", min.node.size=1
                                     )
               )
rfFit
```

We tried 1, 4, 7, and 10 for the mtry - it is hard to choose the best model because of accuracy and kappa. it looks like 10 might be the best because it has a similar accuracy to 4 and 7, but the highest kappa.

#### Mtry 4 and mtry 10 are the two potential best models!

mtry Accuracy Kappa

1 0.8606633 0.00000000

4 0.8612940 0.05652040

7 0.8611419 0.08646859

10 0.8606858 0.10177019

#### Now, lets rename it as the best mtry.

```{r}
set.seed(10)
rfFit_best_mtry <- train(Diabetes_factor ~ Age_factor + Sex_factor + HvyAlcoholConsump_factor + PhysActivity_factor + HighChol_factor + HighBP_factor + GenHlth_factor + AnyHealthcare_factor,
               data = train,
               method = "ranger",
               trControl = trainControl(method = "cv",
                                        number = 3),
               preProcess = c("center", "scale"),
               tuneGrid = data.frame(mtry = 10, splitrule="gini", min.node.size=1
                                     )
               )
rfFit_best_mtry
```

```{r}
rfFit_best_predict <- predict(rfFit_best_mtry, test)

```

```{r}
summary(rfFit_best_predict)
```

```{r}
confusionMatrix(rfFit_best_predict, test$Diabetes_factor)
```

```{r}
confusionMatrix(log3_predict, test$Diabetes_factor)
```

```{r}
confusionMatrix(my_tree_3_predict, test$Diabetes_factor)
```

```{r}
confusionMatrix(rfFit_best_predict, test$Diabetes_factor)
```

```{r}
# THIS IS WHAT I TYPED INTO MY COMPUTER TERMINAL
# docker image ls
# docker run -p 8000:8000 rapi
# http://127.0.0.1:8000/
```
