---
title: "ST558 Final Project Modeling Document"
author: "Kyra Kapsaskis"
format: html
editor: visual
---

# Splitting the data into a test and training set

```{r}
help("createDataPartition")
```


```{r}
# set a seed for reproducibility
set.seed(101)

#indices to split on
# train <- sample(1:nrow(heart_data), size = nrow(heart_data)*0.8)
# test <- dplyr::setdiff(1:nrow(heart_data), train)

#subset
# heartTrain <- heart_data[train, ]
# heartTest <- heart_data[test, ]

split <- createDataPartition(y = factor_data$Diabetes_factor, p = 0.7, list = FALSE)
train <- factor_data[split, ]
test <- factor_data[-split, ]


```

# fit three candidate logistic regression models and choose the best model using CV with log-loss as your metric.

```{r}
help(trainControl)
```


```{r}
# defining cv arguments that will be used as an argument inside each model function

cv_settings <- trainControl(method = "cv", number = 5, summaryFunction = mnLogLoss, classProbs = TRUE) #need to change this to five
```

## First Logistic Regression
```{r}
install.packages("rpart")
```
```{r}
library(rpart)
```


```{r}
# running three separate logistic regressions with different predictors
```

```{r}

my_logreg_1 <- train(Diabetes_factor ~ Sex_factor + Age_factor, 
                     data = train, 
                     method = "glm",
                      
                     trControl = cv_settings,
                     metric = "logLoss")

log1_predict <- predict(my_logreg_1, test)

summary(log1_predict)

```

## Second Logistic Regression

```{r}

my_logreg_2 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")

my_logreg_2

log2_predict <- predict(my_logreg_2, test)

summary(log2_predict)

```
```{r}
# random testing out the describe function
describe(factor_data$Diabetes_factor)
```

## Third Logistic Regression

```{r}

my_logreg_3 <- train(Diabetes_factor ~ MentHlth + Sex_factor + Age_factor + Fruits_factor + GenHlth_factor, 
                     data = train, 
                     method = "glm", 
                     trControl = cv_settings,
                     metric = "logLoss")

log3_predict <- predict(my_logreg_3, test)

summary(log3_predict)
```

## Confusion Matrices

```{r}
confusionMatrix(log1_predict, test$Diabetes_factor)
confusionMatrix(log2_predict, test$Diabetes_factor)
confusionMatrix(log3_predict, test$Diabetes_factor)
```


# Tree models

```{r}
library(tidyverse)
library(haven)
library(knitr)
library(rgl)
library(tree)
library(caret)
```

```{r}
# one tree and one rf, put a lot more predictors, change tunegrid for this and 
```


```{r}
my_tree <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.1, 0.001)))


my_tree_predict <- predict(my_tree, test)

summary(my_tree_predict)

```

```{r}
my_tree_2 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.5, 0.01)))


my_tree_2_predict <- predict(my_tree_2, test)

summary(my_tree_2_predict)
```
```{r}
my_tree_3 <- train(Diabetes_factor ~ PhysHlth + HighChol_factor + Smoker_factor + GenHlth_factor,
                data = train, 
                method = "rpart", 
                trControl = cv_settings,  
                tuneGrid = expand.grid(cp = seq(0, 0.01, 0.0001)))

my_tree_3_predict <- predict(my_tree_3, test)

summary(my_tree_3_predict)
```

```{r}
#Confusion Matrices

confusionMatrix(my_tree_predict, test$Diabetes_factor)
confusionMatrix(my_tree_2_predict, test$Diabetes_factor)
confusionMatrix(my_tree_3_predict, test$Diabetes_factor)
```

```{r}
install.packages("ranger")
```
```{r}
library(ranger)
```


# Random Forest

```{r}

# put a lot of predictors, mtry is a sequence EXAMPLE MAYBE...seq(1, 10, 3)
# just one 
# then pick between logistic 1, 2, 3, tree parameter 1, 2, 3, and rf which mtry was best
set.seed(10)
rfFit <- train(Diabetes_factor ~ Age_factor + Sex_factor + HvyAlcoholConsump_factor + PhysActivity_factor,
               data = train,
               method = "ranger",
               trControl = trainControl(method = "cv",
                                        number = 3),
               preProcess = c("center", "scale"),
               tuneGrid = data.frame(mtry = 1:4, splitrule="gini", min.node.size=1
                                     )
               )
rfFit
```


